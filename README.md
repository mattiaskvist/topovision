# TopoVision

**AI-assisted extraction of 3D terrain models from 2D topographical maps.**

![Python](https://img.shields.io/badge/python-3.12+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-Deep%20Learning-red)
![Status](https://img.shields.io/badge/Status-Research%20Prototype-informational)

---

## üìñ About the Project

**TopoVision** is a research initiative by the **KTH AI Society** in collaboration
with **ReGen Villages**. The project explores how far we can automate the
conversion of 2D contour maps into usable 3D terrain assets with computer vision.

<img width="965" height="540" alt="topovision-workflow" src="https://github.com/user-attachments/assets/002d342f-734a-42eb-9c77-4247a6287abe" />

## ‚úÖ Project Snapshot

**What works today**

- **Synthetic data generation** with Perlin noise, masks, and COCO annotations.
- **Training pipeline** for contour segmentation (U-Net), runnable locally or on
  Modal.
- **Prototype height-extraction pipeline** that combines EasyOCR + U-Net to
  visualize contours and export meshes.

**What is still experimental**

- OCR-to-contour matching and height inference on real-world scans.
- End-to-end performance across different map styles (expect variability).

---

## üöÄ Quickstart

This project uses `uv` for dependency management.

```bash
uv sync
```

### End-to-End Demo (Prototype)

```bash
uv run python tools/run_demo.py --device mps
```

The demo:

- Downloads default U-Net weights from Hugging Face if needed.
- Runs EasyOCR + U-Net over a sample tile.
- Writes outputs to `output/demo/`:
  - `*_predicted_mask.png`
  - `*_result.png`
  - `*_mesh.obj`
- Optional: add `--render-mesh` to open the 3D viewer.

The demo defaults to tiles generated by `process_data` under `data/training/`.
If you need to regenerate them:

```bash
uv run python src/data_pipeline/process_data.py \
  --input data/N60E013/N60E013.shp \
  --output data/training
```

---

## üó∫Ô∏è GIS Tile Generation (process_data)

The main data pipeline renders map tiles and masks from GIS contour sources:

```bash
uv run python src/data_pipeline/process_data.py \
  --input data/N60E013/N60E013.shp \
  --output data/training
```

Tiles are written to `data/training/<tile_name>/`.

---

## üß™ Synthetic Data Generation

Generate synthetic contour maps with rotated text annotations for OCR and
segmentation training:

```bash
uv run python src/data_pipeline/perlin_noise_generator.py
```

Outputs are saved to `data/synthetic/perlin_noise` and include:

- **Images** (`*_image.png`)
- **Masks** (`*_mask.png`)
- **Debug images**
- **COCO annotations** (`coco_annotations.json`)

---

## üß† Training

Training instructions live in `src/training/README.md`, including local and
Modal GPU workflows.

---

## üß∞ Development Setup

Install pre-commit hooks (optional but recommended):

```bash
uv run pre-commit install
```

Run hooks manually:

```bash
uv run pre-commit run --all-files
```

---

## üë• Contributors & Affiliations

**Research Team:**

- Mattias Kvist ‚Äì Research Lead
- Erik Lidman Hillbom ‚Äì Researcher
- Edoardo de Cal ‚Äì Researcher

**Affiliations:**

- [KTH AI Society](https://kthais.com)
- [ReGen Villages](https://www.regenvillages.com)

**Project Timeline:** Nov 2025 ‚Äì Feb 2026  
[View Project Board](https://github.com/users/mattiaskvist/projects/4)
